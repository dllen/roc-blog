<!doctype html><html class=scroll-smooth lang=en><head><meta charset=utf-8><link href=/css/style.css rel=stylesheet><link href=/line-awesome/css/line-awesome.min.css rel=stylesheet><script defer src=/js/main.js></script><title>HDFS 源码阅读：13. 文件写入流程 (Write Path) | 码农的自留地</title><body class="bg-white dark:bg-slate-900 transition ease-in-out"><section><div class="sticky top-0 bg-slate-100 dark:bg-slate-800"><div class="container mx-auto px-auto xl:px-0 w-full xl:w-1/2 flex place-content-between py-16 xl:py-8 font-sans text-6xl xl:text-2xl text-slate-900 dark:text-slate-300"><div class=flex><a class="m-0 p-0 text-slate-900 hover:text-slate-700 dark:text-slate-300 dark:hover:text-slate-200" href=/blog/> /blog </a><a class="m-0 p-0 text-slate-900 hover:text-slate-700 dark:text-slate-300 dark:hover:text-slate-200" href=/blog/hdfs/> /hdfs </a></div><div class="flex gap-4"><div class="hidden cursor-pointer" id=back-to-top><i class="las la-level-up-alt"></i></div><a href=/><i class="las la-home"></i></a><div class=cursor-pointer id=darkmode-toggle><div class="hidden dark:inline"><i class="las la-sun"></i></div><div class="inline dark:hidden"><i class="las la-moon"></i></div></div></div></div></div><div class="container mx-auto w-full xl:w-1/2 mb-16"><div class="mt-4 font-serif text-slate-600 dark:text-slate-500 text-4xl xl:text-base">2026-01-24</div><h1 class="w-full xl:w-2/3 mt-4 mb-8 font-serif text-8xl xl:text-4xl text-slate-900 dark:text-slate-300">HDFS 源码阅读：13. 文件写入流程 (Write Path)</h1><div class="mt-2 mb-6 flex flex-wrap gap-2"></div><div class="w-100 border-t mb-8 border-slate-300 dark:border-slate-700"></div><div class="prose dark:prose-invert prose-pre:rounded-none prose-headings:bg-amber-100 prose-headings:text-slate-800 dark:prose-headings:bg-indigo-900 prose-headings:font-normal dark:prose-headings:text-slate-300 prose-headings:p-2 prose-headings:w-max prose-headings:font-serif prose-2xl xl:prose-base"><p><code>FileSystem.create()</code> 返回的是 <code>FSDataOutputStream</code>，其底层包装了 <code>DFSOutputStream</code>。<h2 id=1-hong-guan-liu-cheng>1. 宏观流程</h2><ol><li><strong>create (RPC)</strong>: Client 向 NameNode 发送 <code>create</code> 请求。NameNode 检查权限，创建文件元数据（状态为 UNDER_CONSTRUCTION），不分配 Block。<li><strong>write (Local Buffer)</strong>: Client 写入数据，数据先被缓存在本地 Buffer 中。<li><strong>Chunk -> Packet</strong>: Buffer 满（默认 64KB）后，切分为 Packet。<li><strong>addBlock (RPC)</strong>: 当第一个 Packet 准备好发送时，Client 向 NameNode 申请一个新的 Block。NameNode 分配 Block ID 和一组 DataNodes (e.g., A, B, C)。<li><strong>Pipeline Setup</strong>: Client 连接 A，A 连接 B，B 连接 C，建立 Pipeline。<li><strong>Data Streaming</strong>: Client 将 Packet 推送到 Pipeline。<li><strong>Ack</strong>: 收到所有 DN 的 Ack 后，Packet 确认为成功。<li><strong>close (RPC)</strong>: Client 发送 <code>complete</code> 请求，NameNode 确认副本数满足最小要求，关闭文件。</ol><h2 id=2-nei-bu-zu-jian-dfsoutputstream>2. 内部组件 (DFSOutputStream)</h2><p><code>DFSOutputStream</code> 内部有两个核心队列和一个线程：<ul><li><strong><code>dataQueue</code></strong>: 待发送的 Packet 队列。<li><strong><code>ackQueue</code></strong>: 已发送但等待 Ack 的 Packet 队列。<li><strong><code>DataStreamer</code> 线程</strong>: 负责从 <code>dataQueue</code> 取出 Packet，发送到 Pipeline，并处理 Ack。</ul><pre class=giallo style=color:#d8dee9;background-color:#2e3440><code data-lang=java><span class=giallo-l><span style=color:#616e88>// DataStreamer.java (简化)</span></span>
<span class=giallo-l><span style=color:#81a1c1>public void</span><span style=color:#88c0d0> run</span><span style=color:#eceff4>() {</span></span>
<span class=giallo-l><span style=color:#81a1c1>    while</span><span style=color:#eceff4> (</span><span style=color:#81a1c1>!</span><span>closed</span><span style=color:#eceff4>) {</span></span>
<span class=giallo-l><span style=color:#616e88>        // 1. Get packet from dataQueue</span></span>
<span class=giallo-l><span style=color:#8fbcbb>        Packet</span><span> one</span><span style=color:#81a1c1> =</span><span> dataQueue</span><span style=color:#eceff4>.</span><span style=color:#88c0d0>getFirst</span><span style=color:#eceff4>()</span><span style=color:#81a1c1>;</span></span>
<span class=giallo-l><span>        </span></span>
<span class=giallo-l><span style=color:#616e88>        // 2. Setup pipeline (if stage == PIPELINE_SETUP_CREATE)</span></span>
<span class=giallo-l><span style=color:#88c0d0>        setupPipelineForCreate</span><span style=color:#eceff4>()</span><span style=color:#81a1c1>;</span></span>
<span class=giallo-l><span>        </span></span>
<span class=giallo-l><span style=color:#616e88>        // 3. Send packet</span></span>
<span class=giallo-l><span>        blockStream</span><span style=color:#eceff4>.</span><span style=color:#88c0d0>write</span><span style=color:#eceff4>(</span><span>one</span><span style=color:#eceff4>.</span><span style=color:#88c0d0>getBuffer</span><span style=color:#eceff4>())</span><span style=color:#81a1c1>;</span></span>
<span class=giallo-l><span>        </span></span>
<span class=giallo-l><span style=color:#616e88>        // 4. Move to ackQueue</span></span>
<span class=giallo-l><span>        dataQueue</span><span style=color:#eceff4>.</span><span style=color:#88c0d0>removeFirst</span><span style=color:#eceff4>()</span><span style=color:#81a1c1>;</span></span>
<span class=giallo-l><span>        ackQueue</span><span style=color:#eceff4>.</span><span style=color:#88c0d0>addLast</span><span style=color:#eceff4>(</span><span>one</span><span style=color:#eceff4>)</span><span style=color:#81a1c1>;</span></span>
<span class=giallo-l><span style=color:#eceff4>    }</span></span>
<span class=giallo-l><span style=color:#eceff4>}</span></span></code></pre><h2 id=3-responseprocessor>3. ResponseProcessor</h2><p><code>DataStreamer</code> 发送数据的同时，会启动一个 <code>ResponseProcessor</code> 线程来读取 Pipeline 的 Ack。<p>如果收到成功的 Ack，就从 <code>ackQueue</code> 中移除对应的 Packet。<h2 id=4-gu-zhang-chu-li-pipeline-recovery>4. 故障处理 (Pipeline Recovery)</h2><p>如果 Pipeline 中某个 DataNode (比如 B) 挂了，或者网络断了，怎么办？<ol><li><strong>检测</strong>: <code>ResponseProcessor</code> 抛出异常或超时。<li><strong>关闭</strong>: 关闭当前的 Pipeline 连接。<li><strong>重构</strong>: <ul><li>将 <code>ackQueue</code> 中的 Packet 放回 <code>dataQueue</code> 头部（防止数据丢失）。<li>向 NameNode 申请更新 Block 的 GenerationStamp（区分新老数据）。<li><strong>剔除坏节点</strong>: 剩下的节点 (A, C) 组成新的 Pipeline。<li><strong>恢复</strong>: 客户端通知 A 和 C 更新 GenerationStamp，然后继续传输。</ul><li><strong>补充</strong>: 如果剩下的节点数太少（<code>&lt; dfs.namenode.replication.min</code>），可能会向 NameNode 申请新的节点补充进来（Replica Replacement），或者就这样写完，由 NameNode 后续做异步复制。</ol><h2 id=5-zong-jie>5. 总结</h2><p>HDFS 的写入流程设计极其健壮，能够容忍网络抖动和节点故障，保证数据不丢。</div></div></section>