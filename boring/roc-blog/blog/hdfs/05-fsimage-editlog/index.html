<!doctype html><html class=scroll-smooth lang=en><head><meta charset=utf-8><link href=/css/style.css rel=stylesheet><link href=/line-awesome/css/line-awesome.min.css rel=stylesheet><script defer src=/js/main.js></script><title>HDFS 源码阅读：05. 持久化机制 (FsImage & EditLog) | 码农的自留地</title><body class="bg-white dark:bg-slate-900 transition ease-in-out"><section><div class="sticky top-0 bg-slate-100 dark:bg-slate-800"><div class="container mx-auto px-auto xl:px-0 w-full xl:w-1/2 flex place-content-between py-16 xl:py-8 font-sans text-6xl xl:text-2xl text-slate-900 dark:text-slate-300"><div class=flex><a class="m-0 p-0 text-slate-900 hover:text-slate-700 dark:text-slate-300 dark:hover:text-slate-200" href=/blog/> /blog </a><a class="m-0 p-0 text-slate-900 hover:text-slate-700 dark:text-slate-300 dark:hover:text-slate-200" href=/blog/hdfs/> /hdfs </a></div><div class="flex gap-4"><div class="hidden cursor-pointer" id=back-to-top><i class="las la-level-up-alt"></i></div><a href=/><i class="las la-home"></i></a><div class=cursor-pointer id=darkmode-toggle><div class="hidden dark:inline"><i class="las la-sun"></i></div><div class="inline dark:hidden"><i class="las la-moon"></i></div></div></div></div></div><div class="container mx-auto w-full xl:w-1/2 mb-16"><div class="mt-4 font-serif text-slate-600 dark:text-slate-500 text-4xl xl:text-base">2026-01-16</div><h1 class="w-full xl:w-2/3 mt-4 mb-8 font-serif text-8xl xl:text-4xl text-slate-900 dark:text-slate-300">HDFS 源码阅读：05. 持久化机制 (FsImage & EditLog)</h1><div class="mt-2 mb-6 flex flex-wrap gap-2"></div><div class="w-100 border-t mb-8 border-slate-300 dark:border-slate-700"></div><div class="prose dark:prose-invert prose-pre:rounded-none prose-headings:bg-amber-100 prose-headings:text-slate-800 dark:prose-headings:bg-indigo-900 prose-headings:font-normal dark:prose-headings:text-slate-300 prose-headings:p-2 prose-headings:w-max prose-headings:font-serif prose-2xl xl:prose-base"><p>为了保证数据不丢失，NameNode 必须将内存中的元数据持久化到磁盘。<h2 id=1-he-xin-gai-nian>1. 核心概念</h2><ul><li><strong>FSImage</strong>: 某一时刻文件系统元数据的<strong>完整快照</strong>。<li><strong>EditLog</strong>: 记录自上一次 FSImage 以来所有的<strong>写操作</strong>（事务日志）。</ul><p><strong>当前状态 = FSImage + EditLog</strong><h2 id=2-fseditlog-shuang-huan-chong-ji-zhi-double-buffer>2. FSEditLog 双缓冲机制 (Double Buffer)</h2><p>如果每来一个写请求都强制刷盘 (fsync)，性能会非常差。HDFS 采用了双缓冲机制来批量刷盘。<pre class=giallo style=color:#d8dee9;background-color:#2e3440><code data-lang=java><span class=giallo-l><span style=color:#616e88>// FSEditLog.java 核心逻辑</span></span>
<span class=giallo-l><span style=color:#81a1c1>class</span><span style=color:#8fbcbb> FSEditLog</span><span style=color:#eceff4> {</span></span>
<span class=giallo-l><span style=color:#616e88>    // 两个 Buffer</span></span>
<span class=giallo-l><span style=color:#81a1c1>    private</span><span style=color:#8fbcbb> EditsDoubleBuffer</span><span> txBuffer</span><span style=color:#81a1c1>;</span></span>
<span class=giallo-l><span>    </span></span>
<span class=giallo-l><span style=color:#616e88>    // bufCurrent: 当前正在写入的 Buffer</span></span>
<span class=giallo-l><span style=color:#616e88>    // bufReady: 准备刷盘的 Buffer</span></span>
<span class=giallo-l><span style=color:#eceff4>}</span></span></code></pre><p>流程 (<code>logSync</code>):<ol><li><strong>写入</strong>: 多个线程同时往 <code>bufCurrent</code> 写入操作记录。<li><strong>交换</strong>: 当需要刷盘时，抢占锁，交换 <code>bufCurrent</code> 和 <code>bufReady</code>。后续线程写入新的 <code>bufCurrent</code>。<li><strong>刷盘</strong>: 将 <code>bufReady</code> 中的数据一次性写入磁盘（JournalSet）。<li><strong>完成</strong>: 清空 <code>bufReady</code>。</ol><p>这种机制实现了<strong>并发写入内存，串行刷盘</strong>，极大提高了吞吐量。<h2 id=3-journalset-yu-qjm>3. JournalSet 与 QJM</h2><p>EditLog 不仅仅写本地磁盘，为了 HA，通常写到 <strong>JournalNodes (JN)</strong>。<p><code>JournalSet</code> 抽象了输出流。在 HA 模式下，使用 <code>QuorumJournalManager</code>，遵循 Paxos 思想，只要写入大多数（N/2+1）JN 成功即认为成功。<h2 id=4-checkpoint-liu-cheng>4. Checkpoint 流程</h2><p>随着时间推移，EditLog 会越来越大，重启 NameNode 需要回放大量日志，非常慢。因此需要定期 Checkpoint（合并 Image 和 EditLog）。<p>在非 HA 模式下，由 <strong>SecondaryNameNode</strong> 完成。 在 HA 模式下，由 <strong>Standby NameNode</strong> 完成。<p><strong>Standby Checkpoint 步骤</strong>:<ol><li><strong>Roll EditLog</strong>: Active NN 切割日志，生成新的 EditLog segment。<li><strong>Download</strong>: Standby NN 从 JN 拉取最新的 EditLog。<li><strong>Load & Merge</strong>: Standby NN 将 EditLog 回放到自己的内存目录树中（Standby 一直在做这个事以保持同步）。<li><strong>Save FSImage</strong>: Standby NN 将内存状态 dump 成新的 FSImage 文件。<li><strong>Upload</strong>: Standby NN 将新的 FSImage 上传回 Active NN。</ol><p>这样，Active NN 甚至不需要暂停服务，也不消耗 CPU 做合并，就得到了最新的 Image。</div></div></section>