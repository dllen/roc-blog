<!doctype html><html class=scroll-smooth lang=en><head><meta charset=utf-8><link href=/css/style.css rel=stylesheet><link href=/line-awesome/css/line-awesome.min.css rel=stylesheet><script defer src=/js/main.js></script><title>Apache Kafka, Purgatory 与分层时间轮 (Hierarchical Timing Wheels) | 码农的自留地</title><body class="bg-white dark:bg-slate-900 transition ease-in-out"><section><div class="sticky top-0 bg-slate-100 dark:bg-slate-800"><div class="container mx-auto px-auto xl:px-0 w-full xl:w-1/2 flex place-content-between py-16 xl:py-8 font-sans text-6xl xl:text-2xl text-slate-900 dark:text-slate-300"><div class=flex><a class="m-0 p-0 text-slate-900 hover:text-slate-700 dark:text-slate-300 dark:hover:text-slate-200" href=/blog/> /blog </a><a class="m-0 p-0 text-slate-900 hover:text-slate-700 dark:text-slate-300 dark:hover:text-slate-200" href=/blog/translate/> /translate </a></div><div class="flex gap-4"><div class="hidden cursor-pointer" id=back-to-top><i class="las la-level-up-alt"></i></div><a href=/><i class="las la-home"></i></a><div class=cursor-pointer id=darkmode-toggle><div class="hidden dark:inline"><i class="las la-sun"></i></div><div class="inline dark:hidden"><i class="las la-moon"></i></div></div></div></div></div><div class="container mx-auto w-full xl:w-1/2 mb-16"><div class="mt-4 font-serif text-slate-600 dark:text-slate-500 text-4xl xl:text-base">2015-10-28</div><h1 class="w-full xl:w-2/3 mt-4 mb-8 font-serif text-8xl xl:text-4xl text-slate-900 dark:text-slate-300">Apache Kafka, Purgatory 与分层时间轮 (Hierarchical Timing Wheels)</h1><div class="mt-2 mb-6 flex flex-wrap gap-2"></div><div class="w-100 border-t mb-8 border-slate-300 dark:border-slate-700"></div><div class="prose dark:prose-invert prose-pre:rounded-none prose-headings:bg-amber-100 prose-headings:text-slate-800 dark:prose-headings:bg-indigo-900 prose-headings:font-normal dark:prose-headings:text-slate-300 prose-headings:p-2 prose-headings:w-max prose-headings:font-serif prose-2xl xl:prose-base"><h1 id=apache-kafka-purgatory-yu-fen-ceng-shi-jian-lun>Apache Kafka, Purgatory 与分层时间轮</h1><p>Apache Kafka 有一个称为“请求炼狱 (request purgatory)”的数据结构。该炼狱持有任何尚未满足成功标准但尚未导致错误的请求。问题在于：“我们如何高效地跟踪集群中由其他活动异步满足的数万个请求？”<p>Kafka 实现了几种无法立即回复响应的请求类型。例如：<ul><li>带有 <code>acks=all</code> 的生产请求 (produce request) 在所有同步副本确认写入之前不能被视为完成，以保证如果 Leader 失败数据不会丢失。<li>带有 <code>min.bytes=1</code> 的拉取请求 (fetch request) 在至少有一个新字节的数据供消费者消费之前不会被回复。这允许“长轮询”，使得消费者无需忙等待检查新数据的到达。</ul><p>当满足以下任一条件时，这些请求被视为完成：(a) 它们请求的标准已完成，或 (b) 发生超时。<p>任何时候处于飞行状态 (in-flight) 的这些异步操作的数量随着连接数的增加而扩展，对于 Kafka 来说，这通常是数万个。<p>请求炼狱专为处理如此大规模的请求而设计，但旧的实现存在一些缺陷。<p>在这篇博客中，我想解释旧实现的问题以及新实现如何解决它。我还将展示基准测试结果。<h2 id=jiu-de-purgatory-she-ji>旧的 Purgatory 设计</h2><p>请求炼狱由一个超时计时器和一个用于事件驱动处理的观察者列表 (watcher lists) 的哈希映射 (hash map) 组成。当请求因条件未满足而无法立即满足时，它会被放入炼狱中。炼狱中的请求稍后在条件满足时完成，或者在超过请求的超时参数指定的时间时强制完成（超时）。在旧设计中，它使用 Java <code>DelayQueue</code> 来实现计时器。<p>当请求完成时，该请求不会立即从计时器或观察者列表中删除。相反，已完成的请求是在条件检查期间被发现时才删除的。当删除速度跟不上时，服务器可能会耗尽 JVM 堆内存并导致 <code>OutOfMemoryError</code>。<p>为了缓解这种情况，一个单独的线程（称为收割者线程/reaper thread）在炼狱中的请求数量（待处理或已完成）超过配置的数量时，会从炼狱中清除已完成的请求。清除操作会扫描计时器队列和所有观察者列表以查找已完成的请求并将其删除。<p>通过将此配置参数设置得很低，服务器实际上可以避免内存问题。但是，如果服务器过于频繁地扫描所有列表，则必须付出巨大的性能代价。<h2 id=xin-de-purgatory-she-ji>新的 Purgatory 设计</h2><p>新设计的目标是允许立即删除已完成的请求，并显著减少昂贵的清除过程的负载。它需要交叉引用计时器和请求中的条目。此外，强烈希望具有 O(1) 的插入/删除成本，因为每个请求/完成都会发生插入/删除操作。<p>为了满足这些要求，我们基于 <a href=http://www.cs.columbia.edu/~nahum/w6998/papers/ton97-timing-wheels.pdf rel=external>分层时间轮 (Hierarchical Timing Wheels)</a> 设计了一个新的炼狱实现。<h3 id=fen-ceng-shi-jian-lun-hierarchical-timing-wheel>分层时间轮 (Hierarchical Timing Wheel)</h3><p>一个简单的时间轮是一个计时器任务桶 (bucket) 的循环列表。令 <code>u</code> 为时间单位。大小为 <code>n</code> 的时间轮有 <code>n</code> 个桶，可以容纳 <code>n * u</code> 时间间隔内的计时器任务。每个桶保存落入相应时间范围的计时器任务。开始时，第一个桶保存 <code>[0, u)</code> 的任务，第二个桶保存 <code>[u, 2u)</code> 的任务，……，第 n 个桶保存 <code>[u * (n -1), u * n)</code> 的任务。每隔时间单位 <code>u</code>，计时器滴答 (tick) 一次并移动到下一个桶，然后让其中的所有计时器任务过期。因此，计时器永远不会将任务插入当前时间的桶中，因为它已经过期了。计时器立即运行过期的任务。清空的桶随后可用于下一轮，因此如果当前桶对应时间 <code>t</code>，则在一次滴答后它变成对应 <code>[t + u * n, t + (n + 1) * u)</code> 的桶。时间轮的插入/删除（启动计时器/停止计时器）成本为 O(1)，而基于优先队列的计时器（如 <code>java.util.concurrent.DelayQueue</code> 和 <code>java.util.Timer</code>）的插入/删除成本为 O(log n)。请注意，<code>DelayQueue</code> 或 <code>Timer</code> 都不支持随机删除。<p>简单时间轮的一个主要缺点是它假设计时器请求处于距当前时间 <code>n * u</code> 的时间间隔内。如果计时器请求超出此间隔，则为溢出。分层时间轮处理这种溢出。它是一个分层组织的计时轮，将溢出委托给上层轮子。最低层具有最精细的时间分辨率。随着我们在层次结构中向上移动，时间分辨率变得更粗。如果某一层的轮子的分辨率为 <code>u</code> 且大小为 <code>n</code>，则第二层的分辨率应为 <code>n * u</code>，第三层为 <code>n^2 * u</code>，依此类推。在每一层，溢出都委托给高一层的轮子。当高层轮子滴答时，它将计时器任务重新插入到低层轮子中。溢出轮可以按需创建。当溢出桶中的桶过期时，其中的所有任务将递归地重新插入计时器。然后任务被移动到更细粒度的轮子或被执行。插入（启动计时器）成本为 O(m)，其中 <code>m</code> 是轮子的数量，这通常与系统中的请求数量相比非常小，而删除（停止计时器）成本仍然是 O(1)。<h3 id=shi-jian-lun-tong-de-shuang-xiang-lian-biao>时间轮桶的双向链表</h3><p>在新设计中，我们为时间轮中的桶使用了我们自己实现的双向链表。双向链表的优点是，如果我们能访问列表中的链接单元 (link cells)，它允许 O(1) 的列表项插入/删除。<p>计时器任务实例在入队到计时器队列时会将链接单元保存在自身中。当任务完成或取消时，使用任务本身保存的链接单元更新列表。<h3 id=shi-yong-delayqueue-qu-dong-shi-zhong>使用 DelayQueue 驱动时钟</h3><p>一个简单的实现可能会使用一个线程，每隔单位时间唤醒一次并进行滴答操作，检查桶中是否有任务。炼狱的单位时间是 1ms (<code>u</code> = 1ms)。如果请求在最低层的时间轮处很稀疏，这可能会很浪费。通常情况确实如此，因为大多数请求在插入最低层时间轮之前就已经满足了。如果线程仅在有非空桶要过期时才唤醒，那就太好了。新的炼狱通过使用 <code>java.util.concurrent.DelayQueue</code> 来实现这一点，类似于旧实现，但我们入队的是任务桶而不是单个任务。这种设计具有性能优势。<code>DelayQueue</code> 中的项目数以上限为桶的数量，这通常远小于任务数量，因此 <code>DelayQueue</code> 内部优先队列的 offer/poll 操作次数将显著减少。<h3 id=qing-chu-guan-cha-zhe-lie-biao-purging-watcher-lists>清除观察者列表 (Purging Watcher Lists)</h3><p>在旧实现中，观察者列表的清除操作由观察者列表的总大小触发。问题在于，即使没有多少请求需要清除，观察者列表也可能超过阈值。发生这种情况时，会大大增加 CPU 负载。理想情况下，清除操作应由观察者列表中已完成请求的数量触发。<p>在新设计中，已完成的请求会立即以 O(1) 的成本从计时器队列中删除。这意味着计时器队列中的请求数在任何时候都是确切的待处理请求数。因此，如果我们知道炼狱中不同请求的总数（包括待处理请求数和已完成但仍被观察的请求数之和），我们就可以避免不必要的清除操作。跟踪炼狱中不同请求的确切数量并非易事，因为请求可能被观察也可能不被观察。在新设计中，我们估计炼狱中的请求总数，而不是试图维持确切的数量。<p>估计的请求数维护如下：<ol><li>每当观察到一个新请求时，估计的请求总数 <code>E</code> 就会增加。<li>在开始清除操作之前，我们将估计的请求总数重置为计时器队列的大小。<li>如果在清除期间没有请求添加到炼狱中，则 <code>E</code> 是清除后的正确请求数。<li>如果在清除期间有一些请求添加到炼狱中，则 <code>E</code> 增加 <code>E + 新观察到的请求数</code>。这可能是一个高估，因为清除操作期间某些新请求可能已完成并从观察者列表中删除。</ol><p>我们预计高估的几率和高估的量都很小。<h2 id=ji-zhun-ce-shi>基准测试</h2><p>我们比较了两种炼狱实现（当前实现和提议的新实现）的入队性能。这是一个微基准测试。它测量炼狱的入队性能。炼狱与系统的其余部分分离，并使用不执行任何有用操作的伪请求。因此，实际系统中炼狱的吞吐量可能远低于测试显示的数字。<p>在测试中，请求的间隔假定遵循指数分布。每个请求花费的时间取自对数正态分布。通过调整对数正态分布的形状，我们可以测试不同的超时率。<p>滴答大小为 1ms，轮子大小为 20。超时设置为 200ms。请求的数据大小为 100 字节。对于低超时率情况，我们选择 75percentile = 60ms 和 50percentile = 20。对于高超时率情况，我们选择 75percentile = 400ms 和 50percentile = 200ms。每次运行总共入队 100 万个请求。<p>请求由单独的线程主动完成。原本应该在超时之前完成的请求被入队到另一个 DelayQueue 中。一个单独的线程保持轮询并完成它们。不保证实际完成时间的准确性。<p>JVM 堆大小设置为 200m 以重现内存紧张的情况。<p>结果显示在高入队率区域有显著差异。随着目标速率的增加，两种实现最初都能跟上请求。然而，在低超时场景中，旧实现在 40000 RPS（每秒请求数）左右饱和，而提议的实现没有表现出任何显著的性能下降；在高超时场景中，旧实现在 25000 RPS 左右饱和，而提议的实现可达 105000 RPS。<p>新实现的 CPU 使用率明显更好。<p>最后，我们测量了 ParNew 收集和 CMS 收集的总 GC 时间（毫秒）。在旧实现可以维持的入队率区域内，旧实现和新实现没有太大区别。<h2 id=zong-jie>总结</h2><p>在新设计中，我们使用分层时间轮作为超时计时器，并使用计时器桶的 DelayQueue 来按需推进时钟。已完成的请求立即以 O(1) 的成本从计时器队列中删除。桶保留在延迟队列中，但是桶的数量是有界的。并且，在一个健康的系统中，大多数请求在超时之前得到满足，许多桶在从延迟队列中取出之前就变空了。因此，计时器应该很少有较低间隔的桶。这种设计的优点是，计时器队列中的请求数在任何时候都是确切的待处理请求数。这允许我们估计需要清除的请求数。我们可以避免不必要的观察者列表清除操作。结果是我们在请求率方面实现了更高的可扩展性，并且 CPU 使用率要好得多。</div></div></section>