---
title: 大模型提示词工程：从入门到精通
date: "2025-11-13"
update_date: "2025-11-13"
description: 系统化掌握提示词工程的概念、方法、评估与实战
tldr: 全流程提示词工程方法论与案例，含入门、进阶与精通指南
tags: ["LLM", "Prompt Engineering", "AI"]
---

大语言模型（LLM）已成为通用智能应用的核心能力。从软件开发到知识管理、从教育到企业流程自动化，LLM 的价值往往取决于人与模型的“对话界面”质量——**提示词（Prompt）**。

提示词工程（Prompt Engineering）就是围绕这一界面进行系统化设计、编排、优化与评估的技术与方法论。本文将以体系化的方式，带你从零开始掌握这项核心技能。

---

## 第一部分：核心概念与机制

### 什么是提示词？
提示词是**赋予模型任务与边界的指令**。它不仅是简单的问题，更是包含角色设定、目标描述、输入数据、约束条件、输出格式与评估标准的完整上下文。

### 作用机制
*   **引导（Guidance）**：明确任务目标、范围与风格，降低模型自由度，减少跑偏。
*   **结构化（Structuring）**：通过分步骤或模块化描述任务，提升可解释性与稳定性。
*   **约束（Constraint）**：通过输出格式、长度限制、成文风格等约束提升一致性。
*   **上下文供给（Context）**：输入必要背景、术语定义、数据片段或检索知识，提高准确性。

### 通用提示词骨架 (The Framework)
一个高质量的提示词通常包含以下要素（可按需裁剪）：

| 要素 | 说明 | 示例 |
| :--- | :--- | :--- |
| **Role (角色)** | 指定模型身份 | "你是资深 Java 架构师..." |
| **Goal (目标)** | 明确产出指标 | "审查代码并提出性能优化建议..." |
| **Context (背景)** | 提供必要信息 | "这段代码运行在高并发场景下..." |
| **Input (输入)** | 待处理的数据 | (代码片段 / 文本 / 问题) |
| **Steps (步骤)** | 过程与思维链 | "1. 分析复杂度; 2. 识别瓶颈; 3. 给出方案" |
| **Constraints (约束)** | 风格与边界 | "不改变原有逻辑，仅优化性能，使用中文回答" |
| **Output (输出)** | 格式协议 | "Markdown 列表" 或 `JSON` |

---

## 第二部分：入门技巧 —— 清晰与规范

入门阶段的核心是**把话说明白**。模糊的指令产生模糊的结果，清晰的指令产生高质量的结果。

### 1. 结构化表达
使用分隔符（如 ```` ``` ````, `###`, `<<< >>>`）区分指令、上下文和用户输入，防止模型混淆。

### 2. 输出约束
明确指定输出的格式，便于后续处理（程序读取或人工阅读）。

#### ✅ 示例：基础摘要生成
```markdown
# Role
你是资深技术编辑，擅长将长文压缩为要点。

# Goal
从输入文章中提取 5 条关键要点和 1 段摘要。

# Constraints
- 要点每条不超过 20 字
- 摘要 120–180 字
- 风格客观、中性、严谨
- 输出为标准 JSON 格式

# Output Format
{
  "bullets": ["要点1", "要点2", ...],
  "summary": "摘要内容..."
}

# Input Text
<<<ARTICLE>>>
(在此处粘贴文章原文...)
<<<ARTICLE_END>>>
```

---

## 第三部分：进阶技术 —— 推理与诱导

当任务复杂度提升，简单的指令往往不够用。我们需要引入更高级的策略来引导模型进行深层思考。

### 1. 思维链 (Chain-of-Thought, CoT)
要求模型在给出最终答案前，先展示推理过程。这能显著提升数学计算、逻辑推理和复杂分析任务的准确率。

#### ✅ 示例：逻辑推理
```markdown
# Task
解决下面的逻辑问题。

# Instructions
请逐步推理（Let's think step by step），先列出已知条件，推导中间结论，最后给出答案。

# Question
甲乙丙三人，甲比乙大，丙比甲小。请问谁最小？

# Output Format
推理过程：...
最终答案：...
```

### 2. 少样本学习 (Few-Shot Prompting)
通过提供 2-5 个高质量的“输入-输出”示例，让模型快速通过类比学习任务的模式、风格和边界。

#### ✅ 示例：情感分析与归因
```markdown
# Task
对用户评论进行情感分类，并提取原因。

# Examples

输入：这家店服务很好，价格也合理。
输出：{"label": "positive", "reason": "服务好，价格合理"}

输入：等了很久才上菜，味道一般，而且很咸。
输出：{"label": "negative", "reason": "上菜慢，口味差"}

# Current Input
输入：虽然快递有点慢，但东西质量确实不错，超值。
输出：
```

### 3. 指定推理路径 (Structured Reasoning)
不仅仅是让模型“思考”，而是规定它“如何思考”。

#### ✅ 示例：产品需求评审
```markdown
# Context
你是一名产品经理，正在评审新的需求文档。

# Steps
1. **完整性检查**：检查是否缺少用户角色、前置条件或异常流程。
2. **风险评估**：指出可能得性能风险或安全隐患。
3. **可测性分析**：判断需求是否具备明确的验收标准。
4. **建议**：基于以上分析，给出修改建议。

# Input
(需求文档内容...)
```

---

## 第四部分：精通指南 —— 代理与工程化

在生产环境中，提示词往往不是孤立存在的，而是与代码、工具和数据流结合在一起。

### 1. RAG (检索增强生成)
解决模型“幻觉”和知识过时的核心手段。
**模式**：Query -> Search -> Retrieve Context -> **Prompt with Context** -> Generation

#### ✅ 示例：基于文档的问答
```markdown
# Role
你是严谨的技术顾问。

# Constraints
- 仅依据提供的[Document Chunks]回答问题。
- 如果文中未提及，直接回答“无法确定”，严禁编造。
- 引用来源，格式为 [doc_id]。

# Document Chunks
[doc1] Kubernetes 是一个开源容器编排引擎...
[doc2] Pod 是 Kubernetes 中最小的部署单元...

# Question
Pod 和 Node 有什么关系？
```

### 2. 函数调用 (Tool Use / Function Calling)
将大模型作为路由和参数提取器，连接外部世界（API、数据库）。

#### ✅ 示例：汇率查询意图识别
```markdown
# Tools
你可以调用以下函数：
- get_exchange_rate(base_currency, target_currency)

# Task
判断用户意图，如果涉及汇率查询，输出对应的函数调用 JSON；否则直接回答。

# User Input
现在 100 美元能换多少人民币？

# Output
{"tool": "get_exchange_rate", "args": {"base_currency": "USD", "target_currency": "CNY"}}
```

### 3. 迭代与自省 (Self-Correction)
让模型自己充当“评审员”，检查初稿并进行修正。

**模式**：Draft -> Critique -> Refine

---

## 第五部分：评估与模型参数

提示词工程不仅仅是写 prompt，还包括评估和调优。

### 1. 评估维度
*   **正确性**：事实是否准确，逻辑是否闭环。
*   **一致性**：相同输入下，输出格式和风格是否稳定。
*   **鲁棒性**：面对恶意输入或噪声数据的表现。
*   **效率**：Token 消耗与响应延迟。

### 2. 关键推理参数 (Inference Parameters)
这些参数决定了模型的“性格”。

| 参数 | 推荐值 | 说明 |
| :--- | :--- | :--- |
| `temperature` | `0.0 - 0.3` | **严谨任务**（代码、抽取）。输出确定性高。 |
| | `0.7 - 1.0` | **创意任务**（写作、聊天）。输出多样性高。 |
| `top_p` | `1.0` | 通常与 Temperature 二选一调节。 |
| `max_tokens` | 按需 | 防止输出过长或死循环，控制成本。 |
| `stop` | `["\n\n", "```"]` | **结构化输出神器**。遇到指定字符强制停止。 |

---

## 附录：模型训练与微调基础 (Context)

*注：本节适用于需要进行模型微调（Fine-tuning）的进阶读者，普通提示词工程可跳过。*

如果你发现 Prompt 无法满足需求，可能需要考虑微调。以下是关键概念：

*   **Learning Rate (学习率)**: 决定模型学习的步伐。微调时通常比预训练小得多（如 `1e-5`）。
*   **Epochs (轮次)**: 数据集训练的遍数。微调通常只需 3-5 轮，过多会导致过拟合（遗忘通用能力）。
*   **Batch Size (批次大小)**: 影响显存占用和收敛稳定性。
*   **Optimizer**: 推荐 `AdamW`，搭配 `Cosine` 学习率调度。

---

## 总结

提示词工程是从“自然语言”到“机器指令”的翻译艺术。

1.  **入门**：掌握结构化骨架，把任务说清楚。
2.  **进阶**：用 CoT 和 Few-Shot 激发模型潜能。
3.  **精通**：结合 RAG、工具调用和自动化评估，构建鲁棒的 AI 应用。

*参考资源：[Prompt Engineering Guide (dair-ai)](https://www.promptingguide.ai/)*
