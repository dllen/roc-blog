---
title: 大模型提示词工程：从入门到精通
date: "2025-11-13"
update_date: "2025-11-13"
description: 系统化掌握提示词工程的概念、方法、评估与实战
tldr: 全流程提示词工程方法论与案例，含入门、进阶与精通指南
---

引言

大语言模型（LLM）已成为通用智能应用的核心能力。从软件开发到知识管理、从教育到企业流程自动化，LLM 的价值往往取决于人与模型的“对话界面”质量——提示词（Prompt）。提示词工程就是围绕这一界面进行系统化设计、编排、优化与评估的技术与方法论。

本文目标：
- 以体系化方式讲清提示词的概念、作用机制与常用结构
- 提供可落地的入门到进阶写法和优化策略
- 分享评估与迭代方法、设计模式、工具与资源
- 适用人群：对 LLM 有基础认知，期望构建高质量 AI 应用或提高工作效率的工程师、产品与研究人员

参考与权威来源说明：
- Prompt Engineering Guide（dair‑ai）系统汇集了“提示工程、上下文工程（Context Engineering）、RAG 与 AI Agents”的指南、论文、课程与资源，包含 Guides、Notebooks 与 Deep Agents、Context Engineering Deep Dive 等进阶专题，为本文方法论与术语提供权威参考与脉络。


基础知识

提示词（Prompt）的基本概念

提示词是“赋予模型任务与边界的指令”，包括角色设定、目标描述、输入数据、约束条件、输出格式与评估标准等。对话型或指令型模型通过提示词理解任务意图，决定推理路径与输出风格。提示词可嵌入应用（系统提示）、来自用户（用户输入）、来自示例（Few‑shot），也可由工具和外部知识（RAG）增强。

提示词的作用机制

- 引导：明确任务目标、范围与风格，降低模型自由度，减少跑偏
- 结构化：通过分步骤或模块化描述任务，提升可解释性与稳定性
- 约束：通过输出格式、长度限制、成文风格等约束提升一致性
- 上下文供给：输入必要背景、术语定义、数据片段或检索知识，提高准确性
- 反馈与自校正：在提示中加入自检、评审与改写环节，实现迭代优化

常见提示词类型与结构

- 角色＋任务：指定模型“扮演谁”和“要做什么”
- 步骤化（结构化）：用条目或阶段划分复杂任务（分析→规划→生成→校对）
- Few‑shot 示例：提供高质量的输入‑输出示例，诱导模型学习样式与边界
- 工具／检索增强：通过函数调用、文档检索（RAG）补充事实与能力
- 评审／自我反思：要求模型自检、指出风险、给出修正并产出最终稿
- 输出格式约束：要求 JSON、表格或特定字段，便于程序消费

一个通用的提示词骨架（可按需裁剪）：

1) 角色：你是资深 X（领域专家、律师、架构师…）
2) 目标：完成 Y（明确任务边界与产出指标）
3) 背景：提供上下文与术语定义
4) 输入：待处理的数据或问题
5) 过程：分步骤行动计划或推理要求
6) 约束：风格、长度、引用、安全与合规
7) 输出：格式协议（如 JSON schema）
8) 评审：自检清单与修订要求


入门技巧

基础提示词编写方法

- 明确且具体：减少“自由叙事”，给出清晰目标和评估标准
- 使用分隔符：用 ```、<<< >>> 或 [Section] 标示不同片段，降低误读
- 分步骤说明：将复杂任务拆解为可执行的连贯步骤
- 提供小型上下文：关键定义、术语、样例、边界条件
- 约束输出：指定字段、结构与风格，便于自动化处理
- 迭代：通过“生成→评审→再生成”的循环提升质量

示例 1：基础摘要（结构化＋约束输出）

输入：

```
[角色]
你是资深技术编辑，擅长将长文压缩为要点。

[目标]
从输入文章中提取 5 条关键要点和 1 段摘要。

[输入]
<<<ARTICLE>>>
（粘贴文章原文）
<<<ARTICLE_END>>>

[约束]
- 要点每条不超过 20 字
- 摘要 120–180 字
- 风格客观、中性

[输出]
JSON：{"bullets": ["…"], "summary": "…"}
```

示例 2：提取结构化信息（信息抽取）

```
从产品说明中提取字段并用 JSON 返回。
字段：name, price, features[], release_date(ISO)
未找到填 null。仅输出 JSON。

文本：
<<<DOC>>>
（产品说明）
<<<DOC_END>>>
```

示例 3：改写风格（保持事实不变）

```
将输入段落改写为“简洁商务体”，保留事实，避免主观评价。
输出不超过 180 字。
文本：…
```

如何评估提示词效果

- 正确性：事实与计算是否正确（必要时结合检索或工具）
- 一致性：同类输入是否得到稳定结构与风格的输出
- 可用性：是否满足格式、长度与可消费性（JSON/表格）
- 鲁棒性：对噪声、边界案例、长输入的耐受度
- 效率：推理耗时、Token 成本与可扩展性

实践建议：
- 建立用例集（覆盖主流程＋边界输入）做 A/B 对比
- 加入自动化校验（正则、JSON Schema、业务断言）
- 记录错误样例并反向优化提示词与流程


进阶技术

提示词优化策略

- 明确任务分解：分析→计划→执行→复核的阶段化结构
- 强化约束与协议：输出 JSON schema、引用格式、评分维度
- 少样本诱导（Few‑shot）：用高质量示例引导模型学习风格与边界
- 迭代自检：要求模型根据检查清单评审并二次生成
- 指示性推理：通过“思路提示”组织模型的推理路径

高级提示工程技术

1) 思维链（Chain‑of‑Thought, CoT）
- 要求“分步推理”，提升复杂推理与数学题的正确率
- 注意：在产品中可采用“隐式 CoT”（只用于中间推理，不暴露给用户）

示例：

```
请逐步推理并给出最终答案；中间推理不出现在最终输出。
问题：两个数和为 12，差为 4，求两数。
最终仅返回：{"x": a, "y": b}
```

2) 少样本学习（Few‑shot）
- 用 2–5 个高质量样例教模型输出样式与边界

示例：情感分类（含示例）

```
任务：对句子进行情感分类，返回 {label, reason}

示例1：
输入：这家店服务很好，价格也合理。
输出：{"label": "positive", "reason": "服务与价格正向"}

示例2：
输入：等了很久才上菜，味道一般。
输出：{"label": "neutral", "reason": "等待负向，味道一般"}

现在开始：
输入：…
仅返回 JSON。
```

3) 自一致性（Self‑Consistency）
- 多次采样不同推理路径，选择多数一致或评分最高的答案
- 工程实现：N 次生成→聚合（投票/评分）→输出

4) ReAct / 工具使用（Toolformer 思路）
- 将“思考与行动”结合：在推理过程中调用检索、计算或 API
- 通过函数调用约束工具使用：传入参数，验证返回，纳入上下文

示例：函数调用协议

```
你可以调用函数：get_rate(from, to)
当需要汇率时，返回：
{"tool": "get_rate", "args": {"from": "USD", "to": "CNY"}}
随后我会提供函数结果，你继续完成任务。
```

5) 上下文工程与 RAG（Retrieval‑Augmented Generation）
- 通过检索引入权威知识，降低幻觉，提升事实性
- 提示词包含：检索查询构造、片段拼接格式、引用与防幻觉指令

示例：问答（含引用）

```
根据提供的文档片段回答问题；若无依据则回答“无法确定”。
输出结构：{"answer": "…", "citations": ["doc1#p3", "doc2#p1"]}

文档片段：
<<<CHUNK_1>>>…<<<END>>>
<<<CHUNK_2>>>…<<<END>>>

问题：…
```

实际应用案例

案例 1：产品需求评审助手
- 输入：需求草案与非功能性约束（性能、安全、兼容性）
- 提示：阶段化评审（完整性→风险→边界→需求可测性），输出问题清单与修订建议（JSON）
- 价值：覆盖广、结构化输出可直接进入需求跟踪系统

案例 2：客服邮件结构化与回复建议
- 输入：客户邮件原文与知识库检索片段
- 提示：信息抽取（问题类型、紧急程度、产品版本）、对齐政策（退款/升级）、生成回复草稿
- 价值：半自动化与合规控制，降低误解与处理时间

案例 3：技术博客协同写作（含 RAG）
- 输入：选题、参考文献检索片段（含引用）
- 提示：大纲→逐节生成→事实核对→引用插入→最终排版（Markdown/HTML）
- 价值：加速产出，保持可核对性与结构一致性


精通指南

边界与限制

- 幻觉：在缺乏知识或过度自由时编造事实；需通过 RAG、函数调用与明确“无法确定”来抑制
- 一致性与漂移：模型版本、温度与上下文变化导致输出风格漂移；需通过协议与评估集控制
- 安全与合规：提示注入、越权调用与敏感信息泄露；需做输入净化、工具白名单与输出审计
- 成本与延迟：复杂推理与多步生成带来 Token 成本；需做缓存、复用与流程裁剪

专业级设计模式

- 指令‑评审‑再生成（IRR）：先生成初稿，再按检查清单评审并改写→最终稿
- 角色编排：专家协作（作者→审校→事实核查），多角色对话合并输出
- 协议驱动：输出严格遵循 JSON Schema 或 DSL，失败则重试与纠偏
- 规划‑执行‑反思（Plan‑Execute‑Reflect）：先生成计划，执行各步，最后反思与修正
- 多样本投票：对同一任务采样多次，聚合成一致答案

相关工具与资源

- Prompt Engineering Guide（dair‑ai）：系统化指南与资源集合，覆盖提示工程、上下文工程、RAG 与 AI Agents；包含 Guides、Notebooks（如 context caching）与进阶专题（Deep Agents、Context Engineering Deep Dive）。
- 上下文缓存与检索：结合向量数据库与缓存策略，缩短延迟、降低成本
- 评估框架：A/B 测试、自动化断言、LLM‑as‑Judge（注意偏差与防御）
- Agents 与工具使用：通过函数调用与安全沙箱扩展模型能力，避免越权


总结与展望

关键知识点回顾

- 提示词的本质：以结构化方式“限定与赋能”模型，提升正确性与一致性
- 入门技巧：具体明确、分隔与分步、上下文供给、输出约束、迭代优化
- 进阶技术：CoT、Few‑shot、自一致性、工具/检索增强（RAG）
- 精通模式：IRR、角色编排、协议驱动、Plan‑Execute‑Reflect、多样本投票
- 评估与治理：用例集＋自动化断言，兼顾正确性、一致性、鲁棒性与成本

进一步学习建议

- 搭建自己的评估集与提示库，沉淀高质量 Few‑shot 样例
- 引入 RAG 与函数调用，提升事实性与可操作性
- 关注上下文工程与 Deep Agents 等专题，构建“可控、可审计、可扩展”的应用架构

未来展望

- 模型‑工具协同将更紧密：更多函数、工作流与安全沙箱标准化
- 评估与治理平台化：从提示工程走向“数据‑模型‑工具‑评估”的一体化工程
- 上下文工程与缓存：面向长上下文与低延迟的工程优化成为常态
- 负责任 AI：在提示与工作流层面强化安全、合规与可解释性

模型设置

在实际工程中，提示词质量与“模型设置”同样关键。设置可分为两大类：一类是“LLM 推理参数”（影响生成风格、稳定性与成本），另一类是“训练/架构参数”（适用于自行训练或微调模型的场景）。下文分别说明，并提供默认值、推荐范围、配置示例与典型模板。

模型类型选择

| 模型类型 | 适用场景 | 优点 | 局限 | 备注 |
| --- | --- | --- | --- | --- |
| `CNN` | 图像分类、目标检测、局部特征提取 | 并行友好、对局部模式敏感 | 对长距离依赖不敏感 | 经典计算机视觉主力 |
| `RNN`/`LSTM`/`GRU` | 序列建模、时间序列 | 能处理顺序和记忆 | 难并行、长依赖衰减 | 已被 Transformer 大幅替代 |
| `Transformer` | NLP、代码、语音、视觉、跨模态 | 强并行、长距离依赖、可扩展 | 计算/显存开销较高 | LLM/多模态模型主流架构 |

注意：对于 LLM 推理与应用开发，通常选择 `Transformer` 系列；CNN/RNN 更偏向训练/特定任务。

LLM 推理参数（生成阶段）

| 参数 | 默认值（常见） | 推荐范围 | 影响与说明 | 注意事项 | 配置示例 |
| --- | --- | --- | --- | --- | --- |
| `temperature` | `1.0` | `0.0–1.0` | 值越小越确定，越大越多样/创造 | 质量保障任务建议低值；创造性任务可提高 | `{ "temperature": 0.2 }` |
| `top_p` | `1.0` | `0.1–1.0` | 核采样：只从累计概率为 `top_p` 的词元集合采样 | 通常只调整 `temperature` 或 `top_p` 之一 | `{ "top_p": 0.3 }` |
| `max_tokens`/`max_length` | 依提供商限制 | 任务相关 | 限制生成长度，控制成本与防跑偏 | 过小导致截断；过大增加成本 | `{ "max_tokens": 512 }` |
| `stop`/`stop_sequences` | 空 | 任务相关 | 在遇到给定序列时停止生成 | 设计结构化输出时非常有用 | `{ "stop": ["\n\n"] }` |
| `frequency_penalty` | `0.0` | `0.0–2.0` | 按出现次数惩罚重复词元 | 减少重复；与 `presence_penalty` 二选一调整 | `{ "frequency_penalty": 0.8 }` |
| `presence_penalty` | `0.0` | `0.0–2.0` | 对所有已出现词元一视同仁地惩罚 | 增加多样性；与 `frequency_penalty` 二选一调整 | `{ "presence_penalty": 0.6 }` |

警告：
- `temperature` 与 `top_p` 不建议同时大幅调整；优先修改其中一个以便可控地影响多样性与确定性。
- `frequency_penalty` 与 `presence_penalty` 也不建议同时显著提高；避免过度抑制导致输出不连贯。

典型场景配置模板（LLM 推理）

事实性问答（QA）：

```json
{
  "temperature": 0.1,
  "top_p": 0.9,
  "max_tokens": 512,
  "stop": ["\n\n"],
  "frequency_penalty": 0.0,
  "presence_penalty": 0.0
}
```

创意写作（故事/诗歌）：

```json
{
  "temperature": 0.8,
  "top_p": 0.95,
  "max_tokens": 1024,
  "stop": [],
  "frequency_penalty": 0.2,
  "presence_penalty": 0.6
}
```

代码生成与格式化（严格结构）：

```json
{
  "temperature": 0.2,
  "top_p": 0.8,
  "max_tokens": 400,
  "stop": ["```"],
  "frequency_penalty": 0.0,
  "presence_penalty": 0.0
}
```

训练/微调的超参数配置（如自行训练分类/回归模型）

| 参数 | 默认值 | 推荐范围 | 影响与说明 | 注意事项 | 配置示例 |
| --- | --- | --- | --- | --- | --- |
| `learning_rate` | `1e-3`（`Adam`） | `1e-5–1e-2`（`Adam`）/`1e-3–1e-1`（`SGD`） | 学习步幅，过大不收敛，过小训练缓慢 | 与优化器/批次大小强相关 | `{ "learning_rate": 0.001 }` |
| `batch_size` | `32` | `16–256` | 影响稳定性与显存占用 | 大批次需线性增大学习率或用 `LR scaling` | `{ "batch_size": 64 }` |
| `epochs` | `10` | `3–100` | 训练轮次，过少欠拟合，过多过拟合 | 结合早停与验证集曲线确定 | `{ "epochs": 20 }` |

警告：
- 大批次搭配过高 `learning_rate` 易发散；建议使用学习率预热与衰减（`warmup + cosine/step decay`）。
- `epochs` 过高需配合早停（`early_stopping`）与正则化，避免过拟合。

优化器设置

| 优化器 | 关键参数 | 默认 | 适用场景 | 注意事项 |
| --- | --- | --- | --- | --- |
| `SGD` | `lr`, `momentum` | `lr=1e-2`, `momentum=0.9` | 简洁稳健，适合浅层或需要严格泛化的任务 | 可配合 `nesterov` 与学习率调度 |
| `Adam` | `lr`, `betas(0.9,0.999)`, `eps` | `lr=1e-3`, `eps=1e-8` | 收敛快、对超参不敏感 | 可能泛化略差；结合 `weight_decay` |
| `AdamW` | `lr`, `betas`, `weight_decay` | `weight_decay=1e-4` | 将权重衰减与动量解耦，适合深网络 | 通常优于 `Adam` 的泛化 |
| `RMSProp` | `lr`, `alpha` | `lr=1e-3` | 在非凸/噪声较大任务表现平稳 | 现代任务多用 `Adam/AdamW` |

正则化参数

| 正则项 | 默认值 | 推荐范围 | 作用 | 注意事项 | 配置示例 |
| --- | --- | --- | --- | --- | --- |
| `dropout` | `0.1` | `0.1–0.5` | 随机失活，缓解过拟合 | 过高影响表示能力 | `{ "dropout": 0.2 }` |
| `L2`（权重衰减） | `0.0` | `1e-6–1e-3` | 平滑权重、提升泛化 | 建议与 `AdamW` 搭配 | `{ "weight_decay": 1e-4 }` |
| `L1` | `0.0` | `1e-6–1e-3` | 稀疏化参数 | 可能导致稀疏过度 | `{ "l1_coef": 1e-5 }` |

硬件加速选项与分布式训练

| 选项 | 关键参数 | 默认值 | 配置示例 | 注意事项 |
| --- | --- | --- | --- | --- |
| `GPU` | `device`, `mixed_precision` | `device=auto` | PyTorch：`device = cuda if available`；`amp=fp16/bf16` | 确认显存与精度需求 |
| `TPU` | `tpu_cores` | `None` | JAX/TF：设置 Pod 规格与编译选项 | 需特定云/硬件支持 |
| 分布式（DDP） | `backend`, `world_size`, `rank` | `backend=nccl` | `torchrun --nproc_per_node=8` | 需设置环境变量与同步策略 |
| 梯度累积 | `grad_accum_steps` | `1` | `{ "grad_accum_steps": 4 }` | 提升等效批次但影响延迟 |
| 混合精度 | `fp16/bf16` | `false` | `{ "precision": "bf16" }` | 注意数值稳定与运算兼容性 |

典型训练配置模板（YAML）

小规模文本分类（单卡）：

```yaml
model: transformer-small
optimizer: adamw
learning_rate: 0.001
weight_decay: 0.0001
batch_size: 32
epochs: 15
dropout: 0.2
precision: bf16
device: auto
```

中等规模训练（多卡 DDP）：

```yaml
model: transformer-base
optimizer: adamw
learning_rate: 0.0007
weight_decay: 0.0001
batch_size: 64  # 每卡
epochs: 12
dropout: 0.1
distributed:
  backend: nccl
  world_size: 8
  grad_accum_steps: 2
precision: fp16
device: auto
```

重要注意事项

- 先确定目标（事实性 vs 创造性）再设定 `temperature/top_p`；明确输出协议可显著提升稳定性。
- 训练任务优先选择 `AdamW + 适度 weight_decay + 学习率调度`；监控验证集指标并早停。
- 分布式与混合精度需验证数值稳定；复杂流水线建议逐步放宽设置，避免一次性叠加所有优化。

附：可操作的示例代码

示例 A：Python（以通用 LLM SDK 为例，结构化输出）

```python
from typing import Dict, Any

SYSTEM = (
    "你是资深技术编辑。任务：从文章提取要点与摘要。"
    "严格按照 JSON 返回，中文输出。"
)

USER_TEMPLATE = (
    "[约束] 要点每条<=20字；摘要120-180字。\n"
    "[输入]\n{article}\n"
    "[输出] JSON: {{\"bullets\": [..], \"summary\": \"..\"}}"
)

def build_messages(article: str) -> Any:
    return [
        {"role": "system", "content": SYSTEM},
        {"role": "user", "content": USER_TEMPLATE.format(article=article)}
    ]

def parse_json(content: str) -> Dict[str, Any]:
    import json
    return json.loads(content)

# 假设有 client.chat.completions.create 接口
def summarize(client, article: str) -> Dict[str, Any]:
    messages = build_messages(article)
    resp = client.chat.completions.create(model="your-llm", messages=messages)
    return parse_json(resp.choices[0].message.content)
```

示例 B：RAG 提示（问答与引用）

```text
系统：你是严谨的技术顾问。仅依据提供片段回答；无依据则回答“无法确定”。
输出：{"answer": "…", "citations": ["source#p"]}

用户：
文档片段：
<<<DOC1>>>…<<<END>>>
<<<DOC2>>>…<<<END>>>

问题：X 的核心机制是什么？
```

示例 C：Few‑shot 分类（JSON 协议）

```text
任务：对评论进行情感分类，返回 {label, reason}

示例1：
输入：这家店服务很好，价格也合理。
输出：{"label": "positive", "reason": "服务与价格正向"}

示例2：
输入：等了很久才上菜，味道一般。
输出：{"label": "neutral", "reason": "等待负向，味道一般"}

开始：输入：…
仅返回 JSON。
```

最后提醒：提示词工程是工程化学科而非“咒语学”。以数据与评估为驱动、结合上下文工程与工具协同，持续迭代，才能在真实场景中稳定产出高质量结果。